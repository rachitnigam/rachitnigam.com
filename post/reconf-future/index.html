<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="utf-8">
  <meta name="author" content="Rachit Nigam">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title> Compiling for the Reconfigurable Future |  Rachit Nigam </title>
  

  <link rel="icon" href="/flower.svg" type="image/svg+xml">

  <link rel="stylesheet" href=https://rachit.pl/css/normalize.css>
  <link rel="stylesheet" href=https://rachit.pl/css/default.css>
  <link rel="stylesheet" href="https://pro.fontawesome.com/releases/v5.10.0/css/all.css" integrity="sha384-AYmEC3Yw5cVb3ZcuHtOA93w35dYTsvhLPVnYs9eStHfGJvOvKxVfELGroGkvsg+p" crossorigin="anonymous"/>
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.9.1/css/academicons.min.css" integrity="sha512-b1ASx0WHgVFL5ZQhTgiPWX+68KjS38Jk87jg7pe+qC7q9YkEtFq0z7xCglv7qGIs/68d3mAp+StfC8WKC5SSAg==" crossorigin="anonymous"/>

  <!-- Load source code pro -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Source+Code+Pro&display=swap" rel="stylesheet">

  
  <link rel="alternate" type="application/rss+xml" title="RSS" href="https://rachit.pl/post/atom.xml">
  

</head>

<body>
  <header>
    <h1 class="name"><a class="unstyled-link" href="/">Rachit Nigam</a></h1>
    <nav>
      <a class="unstyled-link nav-item" href="/#publications">Publications</a>
      <a class="unstyled-link nav-item" href="/#posts">Posts</a>
      <a class="unstyled-link nav-item" href="/files/resume.pdf">CV</a>
    </nav>
  </header>
  <section class="section">
    <div class="container">
      
<div class="post-header">
<h1 class="title">
  Compiling for the Reconfigurable Future
</h1>
<div class="date">
PhD student laments that computers are not fast enough.
</div>
<p class="date">April 16, 2020</p>
</div>

<div class="post">
<blockquote>
<p>FPGAs, a form of reconfigurable
architectures, already power a large number of datacenter applications. With
FPGA acceleration becoming mainstream, it is the perfect opportunity to think
about programming models for designing next-generation high-performance
hardware.</p>
</blockquote>
<p>Moore’s law is in its death throes. With Global Foundries <a rel="noopener nofollow noreferrer" target="_blank" href="https://www.anandtech.com/show/13277/globalfoundries-stops-all-7nm-development">announcing</a>
that they are no longer pursuing 7nm production nodes, fabrication companies
focusing on <a rel="noopener nofollow noreferrer" target="_blank" href="https://www.anandtech.com/show/15217/intels-manufacturing-roadmap-from-2019-to-2029">incremental improvements</a>, and the end of the
arguably more important <a rel="noopener nofollow noreferrer" target="_blank" href="https://en.wikipedia.org/wiki/Dennard_scaling">Dennard scaling</a>, we’re entering a new
era where general purpose architectures are no longer the solution.
Reconfigurable architectures are one of the hottest research topics and perhaps
hold the key to application-specific hardware acceleration. However, without
a sane programming model, reconfigurable architectures might not achieve the
success they deserve.</p>
<h2 id="reconfigurable-architectures">Reconfigurable Architectures</h2>
<p>Since the dawn of computer architecture, we’ve focused on building processors
that are good at executing <em>every</em> conceivable program. The advances in
pipelined designs, speculative and out-of-order execution all try to
dynamically discover regularity and parallelism in arbitrary programs and
execute them as fast as possible. The performance benefits of these technologies
are inarguable. However, all good things come at a price. In their
single-minded zealotry to improve single threaded performance, processors introduce
an incredible amount of <em>control overhead</em>. Figure 1 shows the energy
breakdown of executing an add instruction. The control dominates the cost of
executing an instruction.</p>
<center>
<figure>
<img src="/img/energy-breakdown.png"
     alt="Energy breakdown of executing an add instruction on 45nm technology.">
</img>
<figcaption>
Fig 1.
Energy breakdown of executing an add instruction from
<a href="https://ieeexplore.ieee.org/document/6757323">
Computing's Energy Problem [Horowitz, 2014]
</a>.
</figcaption>
</figure>
</center>
<p>So while modern processors
can execute arbitrary programs quickly, they leave a lot of room for improvement
with an individual program.
Instead of paying for the cost of the general control structures in every program,
what if your processor could pay for the exactly the amount of control required
to execute the current program.
What if you
could <em>reconfigure</em> your architecture
based on the currently executing program?
Reconfigurable architectures refers to the general class of architectures
that allow some degree of application-specific reconfigurability. The term
“reconfigurable architectures” is incredibly broad and spans everything from
the reconfigurability of meshes in <a rel="noopener nofollow noreferrer" target="_blank" href="http://opencelerity.org/">massive many-cores</a> to bit-level
reconfigurable architectures. In this post, we’ll be focusing on Field
Programmable Gate Arrays (FPGAs) as a reconfigurable accelerator.</p>
<h2 id="fpgas-as-computational-accelerators">FPGAs as Computational Accelerators</h2>
<p>FPGAs were initially developed as high-performance simulators for circuit
designs. Testing a hardware design requires simulating its behavior over
thousands of clock cycles. With larger and more complex, the computational
power required to simulate and track the state of a design becomes increasingly
hard. Unfortunately, simulating a hardware design on a traditional processor
does not scale—imagine trying to simulate an i3
processor on a Pentium 4. FPGAs were designed as simulation accelerators. They
provide <em>bit-level</em> reconfigurability which allows them to simulate wires and
gates in a hardware design.</p>
<p>The bit-level reconfigurability also made FPGAs
viable as a cheaper, low-volume alternate to application specific integrated
circuits (ASICs). Instead of taping-out custom chips, FPGAs could be used to
prototype and integrate such accelerators without paying for a full
silicon tape-out. In domains like
signal processing or networking, where real-time deadlines really matter and
CPUs struggle to meet high-throughput requirements, FPGAs were successfully
used as computational accelerators. The common thread in all of these use cases
is that we really want to design custom circuits but don’t want to pay the
costs of producing a whole new chip.</p>
<p>FPGAs happily chugged along in these niche roles for a long time without taking
off in a big way. Researchers knew that FPGAs could play a big role as flexible
accelerators but didn’t have a “killer app”. Between 2010-2016, an exceptional
team of computer architects demonstrated
that FPGAs could be used as
computational accelerators <em>inside datacenters</em> through the <a rel="noopener nofollow noreferrer" target="_blank" href="https://www.microsoft.com/en-us/research/project/project-catapult/">Catapult</a>
project. Catapult, and its successor <a rel="noopener nofollow noreferrer" target="_blank" href="https://www.microsoft.com/en-us/research/project/project-brainwave/">BrainWave</a>, showed that not only can
FPGAs significantly improve the performance of modern large-scale applications,
they provide enough flexibility to be used in multiple domains, accelerating
everything from Bing search, Azure cloud network, and most recently, ML models.</p>
<p>Other cloud services like AWS have jumped on this trend and now offer <a rel="noopener nofollow noreferrer" target="_blank" href="https://aws.amazon.com/education/F1-instances-for-educators/">F1
instances</a> which provide access to high-end FPGA units through AWS’s
pay-what-you-use model.</p>
<h2 id="fpga-programming-101">FPGA Programming 101</h2>
<p>Owing to its root as a hardware simulator, FPGA programming toolchains repurpose
existing hardware design languages (HDLs). As a circuit simulator, this is
a really good idea. You can simply take your preexisting hardware design and
run it on an FPGA.<span style="white-space:nowrap">
<label for="sn-1"
       class="margin-toggle sidenote-number">
</label>
</span>
<input type="checkbox"
       id="sn-1"
       class="margin-toggle"/>
<span class="sidenote">
I apologize to my architect friends. Running designs on an FPGA in reality can be an incredible challenge. FPGAs have different kinds of memory and performance characteristics. Most hardware design codebases are carefully engineered to separate FPGA-specific design decisions from the core design.
</span>
</p>
<p>Unfortunately, when trying to run high-level application code
the level of abstraction afforded by HDLs is far too low-level.
Imagine
trying to write a convolution kernel by specifying every wire connection
into every adder and the computation that occurs at every clock cycle. Proponents
of HDLs will point out that we can eek out every bit of performance from a
low-level hardware design. However, this also means that design iteration times
are much worse. It can take many weeks of engineering effort to implement
and optimize a design.</p>
<p>I am by no means the first person to point this productivity-performance
trade-off. Practitioners and researchers have created a multitude of
HDLs to improve the level of abstraction: <a rel="noopener nofollow noreferrer" target="_blank" href="https://bluespec.com/">BlueSpec</a>, <a rel="noopener nofollow noreferrer" target="_blank" href="https://en.wikipedia.org/wiki/SystemVerilog">SystemVerilog</a>, <a rel="noopener nofollow noreferrer" target="_blank" href="https://github.com/cornell-brg/pymtl3">PyMTL</a>,
<a rel="noopener nofollow noreferrer" target="_blank" href="https://www.chisel-lang.org/">Chisel</a>, etc. all aim to use host languages to improve the level of abstraction
in some manner. For example, Chisel is embedded in Scala and provides
modularity and parameterization mechanisms using Scala’s type system.
However, HDLs still <em>fundamentally</em> operate at the gate-and-wire
level of abstraction. Chisel designs, after being typechecked by the Scala
compiler, are expanded into a structural specification of the hardware design.</p>
<p>A more radical technique to lift the level of abstraction would be to specify
<em>how</em> the computation occurs and use a compiler to generate the hardware for
that specification. The architecture community has been exploring the idea
of transforming behavioral (or functional) descriptions of computation
into hardware designs. This is commonly referred to High-Level Synthesis (HLS)
in the community.</p>
<h2 id="high-level-synthesis">High-Level Synthesis</h2>
<p>High-Level Synthesis<span style="white-space:nowrap">
<label for="sn-2"
       class="margin-toggle sidenote-number">
</label>
</span>
<input type="checkbox"
       id="sn-2"
       class="margin-toggle"/>
<span class="sidenote">
“Synthesis” is borrowed from hardware design workflows—circuits are synthesized into silicon. This is just a compiler.
</span>
 is the idea of compiling a computational description
in a high-level programming language, <span style="white-space:nowrap">
<label for="sn-3"
       class="margin-toggle sidenote-number">
</label>
</span>
<input type="checkbox"
       id="sn-3"
       class="margin-toggle"/>
<span class="sidenote">
Architects operate at the level of gates, wires, and clocks. C++ is a huge
jump in abstractions.
</span>
 like C or C++, into an HDL like
Verilog. HLS has been quite successful in a multitude of domains—everything
from <a rel="noopener nofollow noreferrer" target="_blank" href="https://ieeexplore.ieee.org/document/1466178">digital signal processing</a> to <a rel="noopener nofollow noreferrer" target="_blank" href="https://dl.acm.org/doi/10.1145/3020078.3021741">machine learning
accelerators</a> has been implemented in HLS.</p>
<p>The semantic gap between a functional description and timed hardware structures
is quite large. Hardware designs are <em>timed</em> because they explicitly describe
the
behavior of individual circuits at the granularity of clock cycles. An HLS
compiler needs to transform the functional description into a <em>data path</em>,
which describes the hardware structures that perform computations, and
a <em>control path</em>, which describes the computation performed by components every
cycle.</p>
<p>The promise of transforming <em>any</em> C++ program into hardware is absurd at its
face. C++ programs dynamically allocate memory, use complicated control
structures, and are notoriously hard to analyze. Compare this to physical
hardware where memory sizes and control structures need to statically generated
at compile time.</p>
<p>I’ll leave the specifics of where HLS fails for a future blog post. If you’re
curious, dive into <a href="/files/pubs/dahlia.pdf">our paper</a> on <a rel="noopener nofollow noreferrer" target="_blank" href="https://capra.cs.cornell.edu/dahlia">Dahlia</a> which identifies
some of these problems and shows how little bit of programming languages magic
can help.</p>
<p>If you’re curious about this area, jump onto these cool blog posts and papers:</p>
<ul>
<li><a rel="noopener nofollow noreferrer" target="_blank" href="https://www.cs.cornell.edu/~asampson/blog/fpgaabstraction.html">FPGAs Have the Wrong Abstraction</a> by Adrian Sampson.</li>
<li><a rel="noopener nofollow noreferrer" target="_blank" href="https://ieeexplore.ieee.org/document/5737854?tp=&amp;arnumber=5737854">High-Level Synthesis for FPGAs: From Prototyping to Development</a>.</li>
<li><a rel="noopener nofollow noreferrer" target="_blank" href="https://www.microsoft.com/en-us/research/wp-content/uploads/2016/10/Cloud-Scale-Acceleration-Architecture.pdf">A Cloud-Scale Acceleration Architecture</a>.</li>
</ul>
<p>(If you’ve written a blog post on HLS-related stuff, email it to me so I can
add it here!)</p>
<p><em>Thanks for <a rel="noopener nofollow noreferrer" target="_blank" href="http://adriansampson.net">Adrian Sampson</a> and <a rel="noopener nofollow noreferrer" target="_blank" href="https://www.cs.cornell.edu/~avh/">Alexa VanHattum</a> for providing feedback on early
drafts of this blog post</em>.</p>
<p><em>Have comments? <a href="mailto:rachit.nigam12@gmail.com">Email</a> or <a rel="noopener nofollow noreferrer" target="_blank" href="https://twitter.com/notypes">tweet</a> at me.</em></p>

</div>


    </div>
  </section>

<footer>
  &copy;&nbsp;2021 Rachit Nigam &middot; Built using <a href="https://www.getzola.org/">Zola</a>
</footer>
</body>

</html>
